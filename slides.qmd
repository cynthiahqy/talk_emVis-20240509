---
title: "Provenance for Multi-Source Datasets"
subtitle: "EmVIS Lab Meeting, 9 May 2024"
author: 
  - name: "Cynthia A. Huang"
    affiliation:
    - "Department of Econometrics and Business Statistics, MBUS"
bibliography: references.bib
format: 
  revealjs: 
    theme: [default, _extensions/EmilHvitfeldt/letterbox/letterbox.scss, _extensions/numbats/monash/assets/monash.scss]
    css: [style/custom.css]
    include-after-body: _extensions/EmilHvitfeldt/letterbox/theme.html
    width: 1280
    height: 720
    slide-number: c/t
    title-slide-attributes: 
      data-background-image: "_extensions/numbats/monash/images/bg-02.png"
      data-background-size: "contain"
      data-background-position: "center"
    template-partials:
      - style/title-slide.html
    # footer: "[cynthiahuang.quarto.pub/iasc-asr-23](https://cynthiahuang.quarto.pub/iasc-asr-23)"
---

<!---- todo: use this as template for LMU talk as well --->

# Introduction

## About Me!

::: incremental
- ðŸ‘©â€ðŸŽ“ PhD Candidate in Econometrics & Business Statistics, Monash Business School
- ðŸ™ Supervised by: Rob Hyndman (EBS), Simon Angus (Econ) and Sarah Goodwin!
- ðŸ‘‹ affiliated at Monash with:
    - NUMBATS (Non-Uniform Monash Business Analytics Team)
    - [SoDa Labs](https://www.monash.edu/business/impact-labs/soda-labs) -- alternative data for social science insights
    - MDFI (Monash Data Futures Institute)
- ðŸ’± Previously: Economics at Unimelb
::: 

## About Me!

::: incremental
- ðŸ“Š Interested in adapting data for research purposes:
    - **web-scraped** retail product & price data for public health research
    - mining wikipedia edit **metadata** for evidence of state-sponsored misinformation
    - train/test sampling strategies for satellite (**image**) deep learning
- ðŸ‘©â€ðŸŽ“ **Provenance and statistical imputation for multi-source datasets**
    - ðŸ‡©ðŸ‡ª SoDa Statistiks at LMU in June
    - ðŸ‡¨ðŸ‡¦ InfoVis group at UBC from Jul-Oct
- ðŸ§—ðŸ»â€â™€ï¸ climber, ðŸŽ™ï¸ regular host on The Random Sample podcast
::: 

## Visualising Multi-Source Harmonisation Logic

::: {.columns}

::: {.column}

- Crossmaps Framework
- CS Research (Collaboration) Opportunities
    - Data provenance communication
    - Interactive data merging (multi-table)
- Other downstream projects

:::
::: {.column}
::: {.fragment}
:::{layout="[[-5,88,-5],[-5,90,-5],[-5,45,45,-5]]" layout-align="center"}

[Domain Problem]{.button-blue}

[Provenance Model]{.button-green}

[Visual Encoding]{.button-blue}

[Interactive Tools]{.button-blue}
:::
:::
:::
:::

::: notes
-   problem set up (borrow Kai's slide)
    - semantics of data preparation -- beyond translating (NLP, glyphs, programming languages)
    - extracting, representing logic of transformations
    - from imperative to declarative specification
-   unified framework
    - dual problems appear when you think about [data imputation model]
        - implementation & validation of logic: sensitivity analysis, statistical properties
        - **communication & visualisation of logic**: code-free implementation interfaces, workflows
-   vis/chi challenges / opportunities
    - extraction of data imputation model (graph computation) from existing scripts
        - track-vec; modifying input rather than diff tracing
    - interactive authoring and modification of data imputation model (i.e. harmonisation logic)
-   domain applications
    -   application 01 --> trade/labour concordance for cross-country comparison
        - xmap workshop paper + sankey layout problem
    -   application 02 --> geographic concordance
        - example from merry; what's the best way to display this information?
    -   application 03 --> causal loop diagrams
        - harmonisation can happen between any sets of "related" objects (i.e. nodes OR links)
:::

# Crossmaps Framework

## Ex-Post Harmonisation [1/2]{.f50}

::: {.columns .v-center-container}

::: {.column width="45%"}

> Ex-post (or retrospective) data harmonization refers to **procedures applied to already collected data to improve the comparability** and inferential equivalence of measures from different studies [@kolczynskaCombiningMultipleSurvey2022]

:::

::: {.column width="55%"}

![Procedures in ex-post harmonisation](images/diagram_ex-post-process.png){#fig-expost-tasks fig-align="center"}

:::

:::

## Ex-Post Harmonisation [2/2]{.f50}

::: {.columns .v-center-container}
::: {.fragment .column width="33%"}
![](images/icon-official-stats.png){fig-align="center" height=200px style="margin: 0; padding: 0; "}

*Defining or selecting mappings between classifications or taxonomies,*
:::

::: {.fragment .column width="33%"}
![](images/icon-database.png){fig-align="center" height=200px style="margin: 0; padding: 0; "}

Implementing and validating mappings on given data,
:::

::: {.fragment .column width="33%"}
![](images/icon-IEEE-VIS.png){fig-align="center" height=200px style="margin: 0; padding: 0; "}

Documenting and analysing the implemented mapping.
:::
:::

## Current Approach: Input/Output Comparison

![](images/diagram_current-prov.png)

## Proposed Alternative: Input & Function Capture

![](images/diagram_crossmaps.png){fig-align="center"}

## Implications (ASC23 Poster)

![](images/poster-section.png){fig-align="center"}

[<https://www.cynthiahqy.com/research/assets/asc-poster.pdf>]{.smaller}

## Contributions

::: {.columns}
::: {.column}
- non-hierarchical provenance task abstraction [c.f. @borsProvenanceTaskAbstraction2019]
- compare with inference/diff-based solutions:
    - smallsets, anteater, COMANTICS etc.
    - translation -> summary/sense-making
:::

::: {.column}

- unified approach to:
    - transformation auditing (data quality)
    - transformation documentation (data provenance)
    - data imputation modelling (statistical robustness)
:::
:::

# Future Work

## Visualisation Concepts

::: {.columns}
::: {.column}
Transformation Logic:
![](images/plot-anzsco-isco-bigraph.png){height=550}
:::
::: {.column}
Merged Dataset Quality:
![](images/isiccomb_rev3_TRUEonly.png)
:::
:::

## Provenance Communication & Tools

:::: {.columns}
::: {.column}
:::{layout="[[-5,88,-5],[-5,90,-5],[-5,45,45,-5]]" layout-align="center"}

[Domain Problem]{.button-blue}

[Provenance Model]{.button-blue}

[Visual Encoding]{.button-green}

[Interactive Tools]{.button-green}
:::
:::

::: {.column}

- *layouts & ordering* (similar to sankey diagram optimisation)
- encoding distribution weights & relation styles
- properties of merged dataset

:::
::::

## Data Wrangling Tools

::: {.columns}
::: {.column}
![](images/xmapR.svg){height=550}
:::
::: {.column}

- implementing graph, matrix & table representation in R, with symbolic (fractional) weights
- *extracting mapping logic from existing scripts*
    - manipulate data input
    - parse AST into computational graph
- *authoring and auditing interfaces for non-technical collaborators*
:::
:::

## Other Projects

- summary properties of the computational graph as a data imputation model
- provenenace model for causal loop diagrams
- multiverse analysis of alternative mapping decisions
- provenance abstraction for statistical sampling vs. database queries

## References

    

